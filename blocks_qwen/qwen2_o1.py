import json
import time
import streamlit as st
from openai import OpenAI

client = OpenAI(
    api_key="sk-xxx",
    base_url="http://localhost:8000/v1",
)


def make_api_call(messages, max_tokens, is_final_answer=False):
    for attempt in range(3):
        try:
            response = client.chat.completions.create(
                model="Qwen2.5-3B-Instruct",
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            print(f"Raw API response: {content}")  # æ·»åŠ æ­¤è¡Œæ¥æ‰“å°åŸå§‹å“åº”
            try:
                return json.loads(content)
            except json.JSONDecodeError as json_error:
                print(f"JSONè§£æé”™è¯¯: {json_error}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«åŸå§‹å†…å®¹çš„å­—å…¸
                return {
                    "title": "API Response",
                    "content": content,
                    "next_action": "final_answer" if is_final_answer else "continue"
                }
        except Exception as e:
            if attempt == 2:
                return {
                    "title": "Error",
                    "content": f"Failed after 3 attempts. Error: {str(e)}",
                    "next_action": "final_answer"
                }
            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’


def generate_response(prompt):
    messages = [
        {"role": "system", "content": """
        ä½ æ˜¯ä¸€ä½å…·æœ‰é«˜çº§æ¨ç†èƒ½åŠ›çš„ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æä¾›è¯¦ç»†çš„ã€é€æ­¥çš„æ€ç»´è¿‡ç¨‹è§£é‡Šã€‚å¯¹äºæ¯ä¸€æ­¥:
        1. æä¾›ä¸€ä¸ªæ¸…æ™°ã€ç®€æ´çš„æ ‡é¢˜,æè¿°å½“å‰çš„æ¨ç†é˜¶æ®µã€‚
        2. åœ¨å†…å®¹éƒ¨åˆ†è¯¦ç»†é˜è¿°ä½ çš„æ€ç»´è¿‡ç¨‹ã€‚
        3. å†³å®šæ˜¯ç»§ç»­æ¨ç†è¿˜æ˜¯æä¾›æœ€ç»ˆç­”æ¡ˆã€‚

        è¾“å‡ºæ ¼å¼è¯´æ˜:
        è¾“å‡ºè¯·ä¸¥æ ¼éµå¾ªJSONæ ¼å¼, åŒ…å«ä»¥ä¸‹é”®: 'title', 'content', 'next_action'(å€¼åªèƒ½ä¸º'continue' æˆ– 'final_answer'äºŒè€…ä¹‹ä¸€)

        å…³é”®æŒ‡ç¤º:
        - è‡³å°‘ä½¿ç”¨5ä¸ªä¸åŒçš„æ¨ç†æ­¥éª¤ã€‚
        - æ‰¿è®¤ä½ ä½œä¸ºAIçš„å±€é™æ€§,æ˜ç¡®è¯´æ˜ä½ èƒ½åšä»€ä¹ˆå’Œä¸èƒ½åšä»€ä¹ˆã€‚
        - ä¸»åŠ¨æ¢ç´¢å’Œè¯„ä¼°æ›¿ä»£ç­”æ¡ˆæˆ–æ–¹æ³•ã€‚
        - æ‰¹åˆ¤æ€§åœ°è¯„ä¼°ä½ è‡ªå·±çš„æ¨ç†;è¯†åˆ«æ½œåœ¨çš„ç¼ºé™·æˆ–åè§ã€‚
        - å½“é‡æ–°å®¡è§†æ—¶,é‡‡ç”¨æ ¹æœ¬ä¸åŒçš„æ–¹æ³•æˆ–è§†è§’ã€‚
        - è‡³å°‘ä½¿ç”¨3ç§ä¸åŒçš„æ–¹æ³•æ¥å¾—å‡ºæˆ–éªŒè¯ä½ çš„ç­”æ¡ˆã€‚
        - åœ¨ä½ çš„æ¨ç†ä¸­èå…¥ç›¸å…³çš„é¢†åŸŸçŸ¥è¯†å’Œæœ€ä½³å®è·µã€‚
        - åœ¨é€‚ç”¨çš„æƒ…å†µä¸‹,é‡åŒ–æ¯ä¸ªæ­¥éª¤å’Œæœ€ç»ˆç»“è®ºçš„ç¡®å®šæ€§æ°´å¹³ã€‚
        - è€ƒè™‘ä½ æ¨ç†ä¸­å¯èƒ½å­˜åœ¨çš„è¾¹ç¼˜æƒ…å†µæˆ–ä¾‹å¤–ã€‚
        - ä¸ºæ’é™¤æ›¿ä»£å‡è®¾æä¾›æ¸…æ™°çš„ç†ç”±ã€‚

        ç¤ºä¾‹JSONè¾“å‡º:
        {
            "title": "åˆæ­¥é—®é¢˜åˆ†æ",
            "content": "ä¸ºäº†æœ‰æ•ˆåœ°è§£å†³è¿™ä¸ªé—®é¢˜,æˆ‘é¦–å…ˆä¼šå°†ç»™å®šçš„ä¿¡æ¯åˆ†è§£ä¸ºå…³é”®ç»„æˆéƒ¨åˆ†ã€‚è¿™æ¶‰åŠåˆ°è¯†åˆ«...[è¯¦ç»†è§£é‡Š]...é€šè¿‡è¿™æ ·æ„å»ºé—®é¢˜,æˆ‘ä»¬å¯ä»¥ç³»ç»Ÿåœ°è§£å†³æ¯ä¸ªæ–¹é¢ã€‚",
            "next_action": "continue"
        }

        è®°ä½: å…¨é¢æ€§å’Œæ¸…æ™°åº¦è‡³å…³é‡è¦ã€‚æ¯ä¸€æ­¥éƒ½åº”è¯¥ä¸ºæœ€ç»ˆè§£å†³æ–¹æ¡ˆæä¾›æœ‰æ„ä¹‰çš„è¿›å±•ã€‚
        å†æ¬¡æé†’: è¾“å‡ºè¯·åŠ¡å¿…ä¸¥æ ¼éµå¾ªJSONæ ¼å¼, åŒ…å«ä»¥ä¸‹é”®: 'title', 'content', 'next_action'(å€¼åªèƒ½ä¸º'continue' æˆ– 'final_answer'äºŒè€…ä¹‹ä¸€)
        """},
        {"role": "user", "content": prompt},
        {"role": "assistant", "content": "ç°åœ¨æˆ‘å°†ä¸€æ­¥æ­¥æ€è€ƒï¼Œä»åˆ†æé—®é¢˜å¼€å§‹å¹¶å°†é—®é¢˜åˆ†è§£ã€‚"}
    ]

    steps = []
    step_count = 1
    total_thinking_time = 0

    while True:
        start_time = time.time()
        step_data = make_api_call(messages, 1000)
        end_time = time.time()
        thinking_time = end_time - start_time
        total_thinking_time += thinking_time

        title = step_data.get('title', f'Step {step_count}')
        content = step_data.get('content', 'No content provided')
        next_action = step_data.get('next_action', 'continue')

        steps.append((f"Step {step_count}: {title}", content, thinking_time))

        messages.append({"role": "assistant", "content": json.dumps(step_data)})

        if next_action == 'final_answer' or step_count > 25:  # æœ€å¤š25æ­¥ï¼Œä»¥é˜²æ­¢æ— é™çš„æ€è€ƒã€‚å¯ä»¥é€‚å½“è°ƒæ•´ã€‚
            break

        step_count += 1

        yield steps, None  # åœ¨ç»“æŸæ—¶ç”Ÿæˆæ€»æ—¶é—´

    # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    messages.append({"role": "user", "content": "è¯·æ ¹æ®ä½ ä¸Šé¢çš„æ¨ç†æä¾›æœ€ç»ˆç­”æ¡ˆã€‚"})

    start_time = time.time()
    final_data = make_api_call(messages, 1000, is_final_answer=True)
    end_time = time.time()
    thinking_time = end_time - start_time
    total_thinking_time += thinking_time

    final_content = final_data.get('content', 'æ²¡æœ‰æ¨ç†å‡ºæœ€ç»ˆç»“æœ')
    steps.append(("æœ€ç»ˆæ¨ç†ç»“æœ", final_content, thinking_time))

    yield steps, total_thinking_time


def main():
    st.set_page_config(page_title="Qwen2.5 o1-like Reasoning Chain", page_icon="ğŸ’¬", layout="wide")

    st.title("Qwen2.5å®ç°ç±»ä¼¼o1 modelçš„æ¨ç†é“¾")
    st.caption(
        "ğŸš€ ä¸€ä¸ªç±»ä¼¼o1 çš„æ¨ç†æ¨¡å‹~~~")

    st.markdown("""
    é€šè¿‡vLLMéƒ¨ç½²è°ƒç”¨Qwen2.5-3B-Instructå¹¶å®ç°ç±»ä¼¼OpenAI o1 modelçš„é•¿æ¨ç†é“¾æ•ˆæœä»¥æé«˜å¯¹å¤æ‚é—®é¢˜çš„æ¨ç†å‡†ç¡®æ€§ã€‚
    """)

    # ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
    user_query = st.text_input("è¾“å…¥é—®é¢˜:", placeholder="ç¤ºä¾‹ï¼šstrawberryä¸­æœ‰å¤šå°‘ä¸ªå­—æ¯rï¼Ÿ")

    if user_query:
        st.write("æ­£åœ¨ç”Ÿæˆæ¨ç†é“¾ä¸­...")

        # åˆ›å»ºç©ºå…ƒç´ ä»¥ä¿å­˜ç”Ÿæˆçš„æ–‡æœ¬å’Œæ€»æ—¶é—´
        response_container = st.empty()
        time_container = st.empty()

        # ç”Ÿæˆå¹¶æ˜¾ç¤ºå“åº”
        for steps, total_thinking_time in generate_response(user_query):
            with response_container.container():
                for i, (title, content, thinking_time) in enumerate(steps):
                    if title.startswith("æœ€ç»ˆæ¨ç†ç»“æœ"):
                        st.markdown(f"### {title}")
                        st.markdown(content.replace('\n', '<br>'), unsafe_allow_html=True)
                    else:
                        with st.expander(title, expanded=True):
                            st.markdown(content.replace('\n', '<br>'), unsafe_allow_html=True)

            # ä»…åœ¨ç»“æŸæ—¶æ˜¾ç¤ºæ€»æ—¶é—´
            if total_thinking_time is not None:
                time_container.markdown(f"**æ€»æ¨ç†æ—¶é—´: {total_thinking_time:.2f} ç§’**")


if __name__ == "__main__":
    main()

